## Optimizer

The Optimizer is a an algorithm used by an ANN to learn. Optimizers are simply methods to minimize error rates. Modern optimizers typically use a variant of gradient descent to minimize errors.

Vertical:

## Types of Optimizers

Here are some popular optimizers:

- Stochastic Gradient Descent (SGD)
- Adaptive Gradient Algorithm (Adagrad)
- Root Mean Square Propagation (RMSprop)
- Adaptive Moment Estimation (Adam)

Vertical:

## Optimizers Compared

![Optimizer Graph](http://3.bp.blogspot.com/-nrtJPrdBWuE/VPmIB46F2aI/AAAAAAAACCw/vaE_B0SVy5k/s1600/Long%2BValley%2B-%2BImgur.gif)
